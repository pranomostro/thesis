% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}

Software often has faults: ways in which the actual behavior of the
software diverges from the intended or specified behavior. Computer
scientists have devised different strategies for finding and removing
bugs: Formal software verification, code reviews, and different types of
testing: unit testing, which tests the behavior of small software modules
(such as classes), model-based testing, which automatically generates
test suites from the specification of a software system, and regression
testing, which re-validates a software after changes have been made,
aiming to show developers whether they have introduced new bugs after
the last change to the software.

%CANDO: add sources for the cost of development & also hopefully long
%execution times for test suites.

Regression testing takes up a significant portion of development cost
(up to 50\%, according to \cite{ramler2006economic}), and the resulting
test suites can grow quite significantly in size and execution time,
which hinders development speed and increases costs.

Similarly, model-based testing suffers from issues of combinatorial explosion, %CANDO: explain?
and the resulting test suites tend to be very big.

To mitigate the costs and runtimes of regression and model-based test
suites, different strategies have been devised: test case selection,
which selects a subset of tests for the current execution of tests,
test suite reduction, which permanently deletes a subset of tests from
the test suite, and test case priorization, which changes the order of
test execution to maximize the amount of faults that is found early in
the test suite execution.

\cite{cruciani2019scalable} presents a new family of test
suite reduction algorithms, called the FAST ("FAST Approaches
to Similarity-based Testing") algorithms (first developed in
\cite{miranda2018fast}), and compares them to the algorithms presented
in \cite{chen2010adaptive}, as well as the greedy additional algorithm
presented in \cite{rothermel2001prioritizing}. They implement 4 algorithms
from the FAST family, 2 from the ART ("Adaptive Random Testing") family
and the greedy additional algorithm, and run the different algorithms
on 10 different test programs and their test suites. They then compare
the performance of the test suite reduction algorithms on 3 different
variables: test suite reduction, fault detection loss, and runtime.

This work then attempts to replicate their findings using the data
from 6 additional open-source projects, as well as adding random
test case selection as a baseline test suite reduction method
to compare the other methods to (following Recommendation 8 from
\cite{khan2018systematic}). Specifically, we rank the algorithms with
respect to their performance in TSR, FDL and runtime, and compare our
rankings to the results from \cite{cruciani2019scalable}. The fact that
our findings mostly replicate the findings in \cite{cruciani2019scalable}
can give researchers and test system designers more reliable information
about which test suite reduction approaches to use and research further.

We first explore the field of test suite reduction, touching on other
methods for dealing with large test suites. We then explain in detail
the algorithms used in \cite{cruciani2019scalable}.

Finally, we attempt to determine how different test suite reduction
strategies compare to each other in terms of time performance, fault
detection loss and magnitude of reduction, and close with thoughts on
further possible approaches to test suite reduction, as well as thoughts
on other issues in the area.
