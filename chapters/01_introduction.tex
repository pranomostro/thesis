% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Introduction}\label{chapter:introduction}

Software often has faults: ways in which the actual behavior of a software
system diverges from the intended (or specified) behavior. Computer
scientists have devised different strategies for finding bugs: Formal
software verification, code reviews, and different types of testing:
unit testing, which tests the behavior of small software modules (such
as classes), model-based testing, which automatically generates test
suites from the specification of a software system, and regression
testing, which re-validates a software after changes have been made,
aiming to show developers whether they have introduced new bugs after
the last change to the software.

%CANDO: add sources for the cost of development & also hopefully long
%execution times for test suites.

Regression testing often takes up a significant portion of development
cost (up to 50\%, according to \cite{ramler2006economic}), and the
resulting test suites can grow quite significantly in size and execution
time, which hinders development speed and increases costs (as far as we
are aware, there is no systematic survey of test suite runtimes in the
industry). This process of growing test suites is mostly independent
of the specific development process used (e.g. Agile or the waterfall
model), and test suite growth is mostly a function of the growth of the
underlying software (with more edge cases and combinations of inputs
needing to be tested).

Similarly, model-based testing suffers from issues of combinatorial explosion,
and the resulting test suites tend to be very big.

To mitigate the costs and runtimes of regression and model-based test
suites, different strategies have been devised (the following list is
not exhaustive): test case selection, which selects a subset of tests for
the current execution, test suite reduction, which permanently deletes a
subset of tests from the test suite, and test case priorization, which
changes the order of test execution to maximize the amount of faults
that are found early in the test suite execution (in this thesis, we
only focus on test suite reduction).

\cite{cruciani2019scalable} presents a new family of test suite reduction
algorithms, called the FAST ("FAST Approaches to Similarity-based
Testing") algorithms (first developed in \cite{miranda2018fast}), and
compares them to the algorithms presented in \cite{chen2010adaptive},
as well as the greedy additional algorithm presented in
\cite{rothermel2001prioritizing}. They implement 4 algorithms from the
FAST family, 2 from the ART ("Adaptive Random Testing") family and the
greedy additional algorithm, and run the different algorithms on the test
suites from 10 different projects and their coverage information. They
then compare the performance of the test suite reduction algorithms on
3 different metrics: TSR (test suite reduction), FDL (fault detection
loss), and runtime.

We first explore the field of test suite reduction, touching on other
methods for dealing with large test suites. We explain in detail the
algorithms used in \cite{cruciani2019scalable}.

We then attempt to replicate their findings using the data
from 6 different open-source projects, as well as adding random
test case selection as a baseline test suite reduction method
to compare the other methods to (following Recommendation 8 from
\cite{khan2018systematic}). Specifically, we rank the algorithms with
respect to their performance in TSR, FDL and runtime, and compare our
rankings to the results from \cite{cruciani2019scalable}. The fact that
our findings mostly replicate the findings in \cite{cruciani2019scalable}
can give researchers and test system designers more reliable information
about which test suite reduction approaches to use and research further.

We close with thoughts on further possible approaches to test suite
reduction, as well as thoughts on other issues in the area.
