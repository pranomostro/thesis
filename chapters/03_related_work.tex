% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Related Work}\label{chapter:related}

%CANDO: Write about regression testing, model-based testing where
%tests are selected from automatically generated test suites?

The literature on handling big test suites is large, and this
summarization will only cover small parts of it. For an older,
but comprehensive overview dividing the field into test-suite
reduction, test case selection and test case priorization, see
\cite{yoo2012regression}. A newer overview focused exclusively on test
suite reduction is \cite{khan2016survey}, which attempts to create a
full taxonomy of test suite reduction frameworks/tools and specifically
their implementions. \cite{khan2018systematic} focuses on the algorithmic
approach (i.e. greedy/clustering/searching/hybrid) of the test suite
reduction system and gives recommendations for future evaluation of test
suite reduction methods.

The methods for improving the runtimes of large test suites discussed
in the literature can be divided into three related approaches
\cite{yoo2012regression}: Test suite minimization (here called test
suite reduction), test case priorization, and test case selection.

%Distinction: Temporary or permanent, adequate or inadequate
%ordered or unordered, recency-aware and recency-unaware.

%Move this to terms & definitions instead?

Let $T=\{t_1, t_2, \dots, t_n\}$ be a set of $n$ tests, and a
set of requirements $R=\{r_1, \dots, r_m\}$. These requirements
can take very different forms: they can correspond to coverage of
lines/branches/functions, parts of an explicit specification that must
be tested, runtimes of individual tests, or faults that were discovered
in the past.

Let $m: T \rightarrow \mathcal{P}(R)$ ($\mathcal{P}(R)$ denoting the
powerset of $R$) a function that maps test cases to the requirements they
test (one test can test multiple requirements, but any requirement needs
only one test case to be fulfilled, i.e. there can be no requirements
that need 2 or more tests to be fulfilled).

\section{Test Case Priorization}

Test case priorization attempts to find a permutation $T' \in S_{T}$
($S_{T}$ being the set of all permutations of T) of test cases that
cover as many requirements as early as possible.

More formally, the test case priorization problem is to find a permutation
$T' \in S_{T}$ so that

$$ \forall T'' \in S_{T}: T' \neq T'' \land \forall i \in 1..n: |\bigcup_{j=1}^{i} m(T'(j))| \geq |\bigcup_{j=1}^{i} m(T''(j))| $$

i.e. finding the optimal ordering of test cases, so that every requirement
is met as soon as possible.

%CANDO Maybe use APFD here instead?

\section{Test Case Selection}

Test case selection attempts to temporarily find a subset of tests that
maximize the fulfilled requirements for a set of of recent changes to
the software.

\cite{yoo2012regression} formulate the problem of test case selection as

"\textit{Given}: The program, P, the modified version of P, P' and a test suite, T. \\
\textit{Problem}: Find a subset of T, T', with which to test P'."

Test case selection usually assumes a high degree of transparency and
the availability of a lot of information about the SUT, such as execution
graphs, coverage information, and sometimes information about the runtimes
of individual tests.

\section{Test Suite Reduction}

Test suite reduction, on the other hand, attempts to permanently reduce
the size of the test suite by removing redundant tests. The distinguishing
feature from test case selection is that it doesn't take into account
recent changes to the code of the SUT, and removes test cases permanently.

%CANDO: create subsubsections here?

Generally, in test suite reduction two different cases are distinguished:
adequate and inadequate reduction.

In adequate test suite reduction, the goal is to find the smallest subset
of $T$ so that all $R$ are satisfied:

$$T_{r}=\underset{T_r}{\hbox{arg min}} |T_{r} \subset T: R=\bigcup_{t_{r} \in T_{r}} m(t_{r})|$$

This goal, however, is rarely fulfilled. Often, the objective is to
keep the resulting test suite as small as possible, since reaching
this optimum is computationally hard (as researchers have remarked
\cite{khan2016urvey}, it is equivalent to the NP-complete set cover
prblem \cite{garey1979computers}.

Researchers have attempted to reduce the size of test suites further,
while still keeping runtimes small and fulfilling the requirements to
a reasonable degree.

Adequate reduction needs the requirements $R$ to be present at the time
of reduction to judge whether all requirements have been fulfilled.

The second method of test suite reduction is the inadequate/budget
one. An inadequate test suite reduction fixes the size of the reduce
test suite to a budget $B=|T_{r}|$. This cannot guarantee that all
requirements are completely fulfilled, but often reduces runtimes and
reduction times significantly.

Inadequate reduction can work without access to the requirements.
For example, the FAST family needs only the content of the testcases to
perform a reduction. However, inadequate reduction gives no guarantees
about the performance of the resulting reduced test suite on fulfilling
the requirements.

Other possible goals of test suite reduction include reducing the total
runtime of the reduced test suite given past runtime information, but
due to the scarcity of information about test runtimes, this goal has
been studied less.

Test case priorization subsumes test suite reduction: Given an ordering
$T'$ of test cases, it is easy to select the first $B$ test cases in the
inadequate scenario or the first $i$ test cases that together fulfill
all requirements in the adequate scenario whilst keeping the number of
selected test cases at a minimum.

\cite{khan2018systematic} distinguishes 4 different types of test
suite reduction approaches: Greedy selection, Clustering, Searching,
and Hybrid methods.

\subsection{Greedy Selection}

Greedy approaches, first introduced by \cite{rothermel2001prioritizing}
(in the context of test case priorization), work by selecting test
cases based on test requirements $R=\{r_1, \dots, r_{m}\}$ (mostly
statement/branch/function coverage).

\cite{khan2018systematic} describe the fully general case of greedy-based
test suite reduction, in which a test case is first selected using
the coverage criterion and a heuristic, and then removed from the test
set and added to the set of the reduced test suite, until the coverage
criterion is completely fulfilled by the reduced test suite.

Two simple heuristics, one described more in detail later, are the total
heuristic (choosing the test with the highest amount of coverage from
the test set) and the additional heuristic (choosing the test with the
highest amount of coverage yet not covered by the reduced test suite).

\subsection{Clustering}

Clustering approaches to test suite reduction attempt to maximize
a distance metric on the resulting test suite. This is achieved by
separating $T$ into disjunctive subsets using a clustering algorithm so
that the difference between the clusters of tests is maximized, and the
difference within clusters of tests is minimized (the difference between
tests being calculated using a distance metric such as the Euclidean
distance or the Manhattan distance). Clustering methods then sample
test cases from the subsets (in the optimal case one representative test
case per subset).

This method doesn't need the test requirements to be available:
many approaches (for example from the FAST family examined in
\cite{miranda2018fast}) calculate the similarity of two test cases using
the string of the test case's source code. However, those approaches can
only be inadequate: The test case strings give no information about when
the requirements are completely fulfilled.

Examples of clustering-based approaches to test suite reduction are
of course the FAST algorithms from \cite{cruciani2019scalable}
and \cite{miranda2018fast}, but also the ART family from
\cite{chen2010adaptive} and the algorithms tested in
\cite{hemmati2010achieving}.

\subsection{Searching}

Search-based methods for test suite reduction evaluate subsets of $T$
($S=\{s_1, \dots s_m\} \subset \mathcal{P}(T)$) using a cost and/or
effectiveness measure $F: S \rightarrow \mathbb{R}$, and then select
the subset of tests that scores best on these measures. Because setting
$S:=\mathcal{P}(T)$ results in an exponential search space, search-based
approaches often use heuristics to prune parts of the search space,
for example very small and very large subsets.

The reduced test suite is then searched using the criterion

$$T_s=\underset{s_i \in S}{\hbox{arg max}} F(s_i)$$

Methods for test suite reduction based on searching are presented in
\cite{coutinho2013test}, and \cite{wang2014cost}.

\subsection{Hybrids and Other Methods}

Hybrid methods for test suite reduction combine different approaches
to test suite reduction to achieve greater performance or speed up
the reduction process. For example, search-based test suite reduction
approaches can be enhanced by creating the subsets $S$ of $T$ by applying
different clustering algorithms.

Other methods that can not be easily classified into any of those
three categories have been proposed in the literature, for example
Integer Linear Programming-based (ILP) solutions, which are used for
multi-objective optimization (e.g. optimizing for high coverage, low
running times and low memory usage of tests). An example for for an
ILP-based test suite reduction system is FLOWER \cite{gotlieb2014flower}.

Another approach presented in the literature, based on reducing
the set-cover problem at the heart of test suite minimization
to a satisfiability problem, is \cite{arito2012application},
which solves instances of test suite minimization problems on SIR
\cite{dosupporting2005} in most cases in less than 2 seconds.
