% !TeX root = ../main.tex
% Add the above to each chapter to make compiling the PDF easier in some editors.

\chapter{Replication Study}\label{chapter:replication_study}

%CANDO: where to put the information about bugs discovered in the original code?

17 pages

\section{Research Questions}

We define five %CANDO: change the number if we add/drop research questions
research questions, adapting three from \cite{cruciani2019scalable}
and adding two further questions.

\subparagraph{Research Question 1.1: Can the relative effectiveness in TSR be replicated on other study objects?}

We care about the size of the reduced test suite, therefore it is valuable
by how much test suites are reduced. We use the TSR metric (defined
in terms and definitions) to evaluate the magnitude of the reduction.
Using the TSR is mostly useful in adequate scenarios, since in inadequate
scenarios, the size of the reduced test suite relative to the original
test suite is fixed. We rank the algorithms using a Kruskal-Wallis test,
taken from \cite{cruciani2019scalable}

\subparagraph{Research Question 1.2: Can the relative effectiveness in FDL be replicated on other study objects?}

\cite{rothermel2002empirical} finds that test suite reduction can severely
compromise fault detection capability. To test whether this is the case,
the FDL metric is used to examine the fault detection capabilities
for the algorithms given new data. We also rank the methods using a
Kruskal-Wallis test.

\paragraph{Research Question 2: Can the relative runtime performance of the different algorithms be replicated?}

Due to using different datasets (of both larger and smaller size), the
absolute runtimes of the different test suite reduction methods can be
expected to be different from the original runs. However, the ordering of
the methods according to runtime is expected to be the same (that is, if
algorithm $X$ was faster than algorithm $Y$ on the old data, we can expect
algorithm $X$ to also be faster than algorithm $Y$ on the new data).

Again, we use the Kruskal-Wallis test to rank methods after their
runtime performance.

\paragraph{Research Question 3: How much better than random selection are specialized algorithms?}

\cite{khan2018systematic} recommends a comparison of the examined
technique to a simple baseline. We use their recommendation (random
selection) and compare the other approaches to how well they fare against
random selection on runtime, TSR and FDL.

\paragraph{(Possibly) Research Question 4: Can the results be reproduced with the original test data?}

\section{Study Design}

\section{Study Objects}

The code bases and test suites selected for this study were small to
medium sized open-source Java projects. They all used either JUnit
4 or JUnit 5 as their testing framework, and the tool Maven %CANDO: right capitalization?
for building and testing. We used the latest version.

We selected java projects because tools for generating coverage
information and mutation-test data using Maven are available and
comparatively easy to use. We decided to use open-source projects to make
checking our generated data easier, as well as for availability reasons.

The selected projects are both under development and in use, which makes
our results relevant to real-life systems.

\section{Selecting Projects}

The projects used, their versions and size are presented in table CANDO
(project and test suite size are in lines of code, the version is the
6-digit prefix of the git commit used).

\begin{table}[htpb]
	\caption[]{}\label{tab:projects} %Project name, version, size of test suite, size of project, link to project
	\centering
	\begin{tabular}{l l l l l l}
		\toprule
		Project name & Version & Project size & Test-suite size & Number of tests \\
		\midrule
		assertj-core & cb2829 & 135k & 241k &3578 \\
		commons-collections & 242918 & 59k & 45k & 238 \\
		commons-lang & 6b3f25 & 51k & 40k & 181 \\
		commons-math & 649b13 & 148k & 98k & 438 \\
		jopt-simple & 5a1d72 & 1.7k & 2.7k & 145 \\
		jsoup & 89580c & 18k & 12k & 52 \\
		\bottomrule
	\end{tabular}
\end{table}

%CANDO: include number of test cases?

\section{Study Setup}

Testing the performance of the algorithms required three different kinds
of information: the contents of the test suites, coverage information
and fault information.

\subsection{Combining Tests Suites}

For every examined project, the test suite was converted into a format
suitable for the code from \cite{cruciani2019scalable} by replacing the
newlines from each test with spaces and concatenating the tests into
one file (the \textbf{black-box file}), such that every line contained
one test case.

For some of the projects, test cases were excluded since they failed
during the default test run:

%CANDO: make second column multi-line

\begin{table}[htpb]
	\caption[]{}\label{tab:excluded} %Project name, excluded tests
	\centering
	\begin{tabular}{l | p{10cm}}
		\toprule
		Project name & Test classes excluded \\
		\midrule
		assertj-core & BDDSoftAssertionsTest, SoftAssertionsTest, SoftAssertions\_overriding\_afterAssertionErrorCollected\_Test, SoftAssertionsErrorsCollectedTest, SoftAssertionsMultipleProjectsTest, SoftAssertions\_setAfterAssertionErrorCollected\_Test, AssertJMultipleFailuresError\_getMessage\_Test \\
		commons-collections & BulkTest \\
		commons-lang & FieldUtilsTest \\
		commons-math & FastMathTest, EvaluationTestValidation \\
		jopt-simple & / \\
		jsoup & / \\
		\bottomrule
	\end{tabular}
\end{table}

\subsection{Generating Coverage Information}

Coverage information was generated using jacoco with the testwise mode
of the teamscale jacoco agent. %CANDO link

Since the teamscale jacoco agent only supports line coverage, other
types of coverage had to be eschewed.

%CANDO: add note about how line coverage subsumes branch & function coverage?

The json files created by the teamscale jacoco agent were converted
from JSON into the format used by \cite{cruciani2019scalable}: a file
containing a list of numbers in each line, with the numbers $n_1, \dots
n_i$ in line $n$ corresponding to the source lines of code in the tested
project covered by the test case at line $n$ in the \textbf{black-box
file}.

\subsection{Collecting Fault Coverage Information}

%Cite Budd TA. Mutation analysis of program test data

Fault detection information was not available for the projects used,
and was therefore generated by mutation testing using the mutation
testing framework pitest.

The generated mutation test data was converted from XML to the format used
in the code of \cite{cruciani2019scalable}: a text file containing a list
of number per line, the numbers at line $n$ corresponding to different
classes for which the test case at line $n$ in the \textbf{black-box file}
did find faults.

\section{Results}

To obtain the results, we used the code from \cite{cruciani2019scalable},
and applied the test suite reduction algorithms to new test data
(i.e. black-box test suite files and coverage information of 6 open source
projects) after minimal modification. These modifications were as follows:

We added a further algorithm for the random selection of test cases.

We fixed three bugs we found in the code: an off-by-one error in loading
coverage information, a bug where in small test suites sometimes the
candidate set would be empty, and a mistake where a a measured variable
was not reported correctly for FAST-all. The changes made to the source
code can be found at CANDO.

In the budget scenario, we considered budgets between 1\% and 30\%, with
a step increase of 1\%. We considered only line coverage (functionally
equivalent to statement coverage), and performed 50 measurements of
FDL, TSR, preparation and reduction time.

In the adequate scenario, we also considered only line coverage, and
made 50 measurements of preparation time, coverage preparation time,
and reduction time.

We did not replicate the large-scale scenario.

All measurements were performed under a Ubuntu 20.04 64-bit system,
using 6 AMDÂ® Ryzen 5 4500u with radeon graphics processors, and 7.2
GiB of RAM available.

\subsection{Research Questions}

\paragraph{Research Question 1.1}

\autoref{tab:tsr_stats} shows the descriptive statistical results
(median, standard deviation and ordering for the Kruskal-Wallis test)
in the adequate case.

\begin{table}[htpb]
	\caption[TSR statistical results, adequate]{Different variables relating to TSR (mdn is the median, $\sigma$ being the standard deviation, and $\delta$ being the ranking in the Kruskal-Wallis test)}\label{tab:tsr_stats}
	\centering
	\begin{tabular}{l l l l}
	Approach & mdn & $\sigma$ & $\delta$ \\
	\midrule
	ART-D & 0.174 & 0.09 & \\
	ART-F & 0.003 & 0.0157 & \\
	FAST++ & 0.34 & 0.135 & \\
	FAST-all & 0.218 & 0.078 & \\
	FAST-CS & 0.32 & 0.121 & \\
	FAST-pw & 0.323 & 0.119 & \\
	GA & 0.391 & 0.149 & \\
	RS & 0.002 & 0.016 & \\
	\bottomrule
	\end{tabular}
\end{table}

\paragraph{Research Question 1.2}

\autoref{tab:fdl_stats} shows the descriptive statistics (mean, median,
standard deviation, and ordering according to the Kruskal-Wallis test)
for the FDL of different algorithms.

%CANDO: merge tables

\begin{table}[htpb]
	\caption[FDL statistical results]{Different variables relating to FDL ($\mu$ being the mean, mdn the median, $\sigma$ the standard deviation, and $\delta$ the ranking in the Kruskal-Wallis test)}\label{tab:fdl_stats}
	\centering
	\begin{tabular}{c | c | c}
	\midrule
	Budget & Adequate \\
	\midrule
	{\begin{tabular}{l | l | l | l}
		Approach & mdn & $\sigma$ & $\delta$ \\
		\midrule
		ART-D & 0.936 & 0.347 & \\ \hline
		ART-F & 0.949 & 0.357 & \\ \hline
		FAST++ & 0.936 & 0.35495 & \\ \hline
		FAST-all & 0.937 & 0.349 & \\ \hline
		FAST-CS & 0.941 & 0.357 & \\ \hline
		FAST-pw & 0.932 & 0.355 & \\ \hline
		GA & 0.705 & 0.334 & \\ \hline
		RS & 0.975 & 0.11 & \\
	\end{tabular}} &
	{ \begin{tabular}{l | l | l | l | l}
		Approach & $\mu$ & mdn & $\sigma$ & $\delta$ \\
		\midrule
		ART-D & 0.002 & 0.0 & 0.01 \\ \hline
		ART-F & 0.0005 & 0.0 & 0.007 \\ \hline
		FAST++ & 0.011 & 0.0 & 0.021 \\ \hline
		FAST-all & 0.003 & 0.0 & 0.006 \\ \hline
		FAST-CS & 0.01 & 0.0 & 0.02 \\ \hline
		FAST-pw & 0.007 & 0.0 & 0.011 \\ \hline
		GA & 0.014 & 0.0 & 0.024 \\ \hline
		RS & 0.0005 & 0.0 & 0.007 \\
	\end{tabular}} \\
	\bottomrule
	\end{tabular}
\end{table}

We include the mean in the descriptive statistics to illustrate that
while the median adequate reduction has no fault detection loss, it can
nonetheless still occur.

\paragraph{Research Question 2}

\paragraph{Research Question 3}

\paragraph{(Possibly) Research Question 4}

\section{Discussion}

Comparison to ''Scalable Approaches to Test Suite Reduction''

\section{Threats to Validity}

Although we attempted to prevent it, the results we obtained might suffer
from threats to validity.

\subsection{Construct Validity}

Construct validity considers whether the methods are adequate to answer
the research questions posed. As in the original paper, we used FDL
and TSR as standard metrics, and reported the mean, median and standard
deviation of the data as standard statistical properties of the generated
data.

\subsection{Internal Validity}

The results we obtained might not be due to actual differences in
the performance of the different methods, but due to other factors,
such as the usage of the computer used for gathering data for other
purposes during that time. To migitate these effects, we performed every
measurement 50 times, and abstained from using the computer during the
time of gathering data.

\subsection{Conclusion Validity}

Threats to conclusion validity are present when false positives are
found due to considering many different test suite reduction methods
and variables. This paper performs 4 %CANDO: update
statistical tests, thus we judge a significance level of 5\% to be
sufficient.

\subsection{External Validity}

The projects we selected are all small to medium-sized projects,
and therefore the results we obtained might not generalize to
large-scale software systems. While one of the projects we obtained
test data from (assertj-core) was larger than the projects examined in
\cite{cruciani2019scalable}, it was not analyzed separately from the
other data. However, since the projects we used were of similar size
as the ones in \cite{cruciani2019scalable}, and our interest was to
replicate their findings, we regard this consideration as less relevant.
